import os
import numpy as np
import librosa
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical


emotion_labels = {
    1: "neutral", 2: "calm", 3: "happy", 4: "sad",
    5: "angry", 6: "fearful", 7: "disgust", 8: "surprised"
}

DATA_PATH = "C:\\new coding folder\\ravdess"

def augment_audio(audio, sr):
    noise = 0.005 * np.random.randn(len(audio))
    shifted = np.roll(audio, int(sr * 0.2))
    return [audio + noise, shifted]

def extract_features(file_path, augment=True):
    audio, sr = librosa.load(file_path, sr=22050)
    features = []

    def extract(x):
        mfcc = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=40)
        chroma = librosa.feature.chroma_stft(y=x, sr=sr)
        contrast = librosa.feature.spectral_contrast(y=x, sr=sr)
        combined = np.concatenate([
            np.mean(mfcc.T, axis=0),
            np.mean(chroma.T, axis=0),
            np.mean(contrast.T, axis=0)
        ])
        return combined

    features.append(extract(audio))
    if augment:
        for aug in augment_audio(audio, sr):
            features.append(extract(aug))

    return features


def load_data(datapath):
    X, y = [], []
    print(f"Looking in: {datapath}")
    for root, _, files in os.walk(datapath):
        for file in files:
            if file.endswith(".wav"):
                try:
                    parts = file.split("-")
                    if len(parts) < 3:
                        print(f"Skipping invalid filename: {file}")
                        continue
                    emotion = int(parts[2])
                    full_path = os.path.join(root, file)
                    print(f"Extracting from: {full_path}, Emotion ID: {emotion}")
                    features_list = extract_features(full_path)
                    for feat in features_list:
                        X.append(feat)
                        y.append(emotion - 1)
                except Exception as e:
                    print(f"Error processing {file}: {e}")
    print(f"Total processed: {len(X)} samples")
    return np.array(X), to_categorical(y)


X, y = load_data(DATA_PATH)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)


model = Sequential([
    Conv1D(64, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Dropout(0.3),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(8, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])


callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    ModelCheckpoint("model/best_model.h5", save_best_only=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)
]


model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=callbacks)

os.makedirs("model", exist_ok=True)
model.save("model/VoiceWhisperer")
